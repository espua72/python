{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = sns.load_dataset('iris')\n",
    "iris\n",
    "X = iris.drop('species', axis=1).values\n",
    "y = iris['species'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf_LR = LogisticRegression(solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_LR.fit(X, y)\n",
    "y_pred = clf_LR.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fxGridSearch(df, target, classifier, params=[], GSopt=\"RandomGridSearch\", scale=None, \n",
    "         simplifiedrpt=True, sortrank=True, cv=5, n_iter=2, rtnTS=False):\n",
    "    \n",
    "    # classifier: the trained Classifier\n",
    "    # cv: cross-validation\n",
    "    # n_inter: number of iteration\n",
    "    # sortrank: sort the performance by rank\n",
    "    # GSopt: Grid Search option, \"GridSearch\" or \"RandomGridSearch\" to perform Hyper-parameter tuning\n",
    "    #        \"RandomGridSearch\" just randomly pick few parameters from the given sets, which is much faster\n",
    "    # scale: 'minmax', 'standard', default is none\n",
    "    # rtnTS: return train score\n",
    "    \n",
    "    import warnings\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.metrics import accuracy_score, confusion_matrix, plot_confusion_matrix, classification_report    \n",
    "    \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    import json\n",
    "    \n",
    "    warnings.filterwarnings('ignore', category=UserWarning) \n",
    "    \n",
    "    classifiername = type(classifier).__name__\n",
    "    hyperparam_opt, docref = '', ''\n",
    "    webref = 'https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/'\n",
    "    \n",
    "    if not params: # no parameters specified, do recommendation\n",
    "        helperlist=[]\n",
    "        \n",
    "        if classifiername=='LogisticRegression':\n",
    "            hyperparam = {'C': [100, 10, 1.0, 0.1, 0.01], 'solver': ['lbfgs', 'liblinear', 'saga', 'sag'], 'l1_ratio':[-1, -0.5, 0, 0.5, 1]}\n",
    "            hyperparam_opt = \"'penalty': ['none', 'l1', 'l2', 'elasticnet']\" + \"  * Not all solvers support all regularization terms.\"                             \n",
    "            docref = 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html'\n",
    "        elif classifiername=='DecisionTreeClassifier':\n",
    "            hyperparam = {'criterion': ['gini', 'entropy'], 'max_depth': [2, 3, 4, 5] }\n",
    "            docref = 'https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html'\n",
    "        elif classifiername=='KNeighborsClassifier':\n",
    "            hyperparam = {'weights': ['uniform', 'distance'], 'metric': ['euclidean', 'manhattan', 'minkowski'] }\n",
    "            hyperparam_opt = \"'n_neighbors': [2, 3, 5, 7, 9]\" + \" * if not optimized with elbow method\"\n",
    "            docref = 'https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html'\n",
    "        elif classifiername=='RandomForestClassifier':\n",
    "            hyperparam = {'max_features':['sqrt', 'log2'], 'n_estimators':[10, 100, 1000] }\n",
    "            docref = 'https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html'\n",
    "        elif classifiername=='SVC':\n",
    "            hyperparam = {'kernel':['linear', 'rbf'], 'C':[0.1, 0.01] }\n",
    "            docref = 'https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html'\n",
    "        elif classifiername=='XGBClassifier':\n",
    "            hyperparam = {'learning_rate': [0.01, 0.1], 'n_estimators': [100, 1000], \n",
    "                          'max_depth': [3, 4, 5], 'subsample': [0.8, 0.1], 'colsample_bytree': [0.3, 0.8],\n",
    "                          'gamma': [0, 1]}\n",
    "            docref = 'https://xgboost.readthedocs.io/en/latest/parameter.html'\n",
    "            webref = 'https://towardsdatascience.com/fine-tuning-xgboost-in-python-like-a-boss-b4543ed8b1e'\n",
    "\n",
    "        # ******** generate helper string ************\n",
    "        helperlist.append(type(classifier).__name__ + ', recommended hyper parameters: \\n')\n",
    "        helperlist.append(json.dumps(hyperparam))\n",
    "        \n",
    "        if hyperparam_opt!='': helperlist.append('optional parameters: ' + hyperparam_opt)\n",
    "        if docref!='': helperlist.append('doc ref: ' + docref)\n",
    "        if webref!='': helperlist.append('web ref: ' + webref)\n",
    "        \n",
    "        helperstr = '\\n'.join(helperlist)\n",
    "        print(helperstr)\n",
    "        return hyperparam\n",
    "    \n",
    "    dfX = df.drop(target, 1)\n",
    "    X = dfX.values\n",
    "    y = df[target].values\n",
    "    #xcols = dfX.columns.tolist()\n",
    "    \n",
    "    if scale=='standard':\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        dfXs = pd.DataFrame(StandardScaler().fit_transform(dfX.values), columns=dfX.columns)\n",
    "        X = dfXs.values\n",
    "    elif scale=='minmax':\n",
    "        from sklearn.preprocessing import MinMaxScaler\n",
    "        dfXs = pd.DataFrame(MinMaxScaler().fit_transform(dfX.values), columns=dfX.columns)\n",
    "        X = dfXs.values\n",
    "        \n",
    "    if GSopt==\"GridSearch\":\n",
    "        # Using stanrd grid search\n",
    "        from sklearn.model_selection import GridSearchCV\n",
    "        clf_GSCV = GridSearchCV(classifier, params, cv=cv, return_train_score = rtnTS)\n",
    "    elif GSopt==\"RandomGridSearch\":\n",
    "        from sklearn.model_selection import RandomizedSearchCV\n",
    "        clf_GSCV = RandomizedSearchCV(classifier, params, cv=cv, return_train_score = rtnTS, n_iter=n_iter)\n",
    "        \n",
    "            \n",
    "    clf_GSCV.fit(X, y)\n",
    "    result = clf_GSCV.cv_results_\n",
    "    df_result = pd.DataFrame(result)\n",
    "    \n",
    "    if simplifiedrpt == True:\n",
    "        cvcols = df_result.columns.tolist()\n",
    "        cvcols_sel = []\n",
    "\n",
    "        for paramstr in cvcols:\n",
    "            if \"param_\" in paramstr:\n",
    "                cvcols_sel.append(paramstr)\n",
    "        cvcols_sel.append('mean_test_score')\n",
    "        cvcols_sel.append('rank_test_score')\n",
    "        \n",
    "        df_result = df_result[cvcols_sel]\n",
    "        colrev = df_result.columns.tolist()\n",
    "        colrev = [item.replace(\"param_\", \"\") for item in colrev]\n",
    "        df_result.columns = colrev\n",
    "        \n",
    "        if sortrank==True:\n",
    "            df_result.sort_values(by=\"rank_test_score\", inplace=True)\n",
    "\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression, recommended hyper parameters: \n",
      "\n",
      "{\"C\": [100, 10, 1.0, 0.1, 0.01], \"solver\": [\"lbfgs\", \"liblinear\", \"saga\", \"sag\"], \"l1_ratio\": [-1, -0.5, 0, 0.5, 1]}\n",
      "optional parameters: 'penalty': ['none', 'l1', 'l2', 'elasticnet']  * Not all solvers support all regularization terms.\n",
      "doc ref: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
      "web ref: https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n"
     ]
    }
   ],
   "source": [
    "params_LR = fxGridSearch(iris, 'species', clf_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>l1_ratio</th>\n",
       "      <th>solver</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>-1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.01</td>\n",
       "      <td>-1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       C l1_ratio     solver  mean_test_score  rank_test_score\n",
       "54     1      0.5       saga         0.986667                1\n",
       "50     1        0       saga         0.986667                1\n",
       "46     1     -0.5       saga         0.986667                1\n",
       "58     1        1       saga         0.986667                1\n",
       "0    100       -1      lbfgs         0.980000                5\n",
       "..   ...      ...        ...              ...              ...\n",
       "89  0.01        0  liblinear         0.666667               96\n",
       "81  0.01       -1  liblinear         0.666667               96\n",
       "93  0.01      0.5  liblinear         0.666667               96\n",
       "97  0.01        1  liblinear         0.666667               96\n",
       "85  0.01     -0.5  liblinear         0.666667               96\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fxGridSearch(iris, 'species', clf_LR, params=params_LR, GSopt=\"GridSearch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "+ using `saga` solver with C=1, l1_ratio: 0.5, 1, -0.5 giving higher accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Decision Tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf_DT = DecisionTreeClassifier()\n",
    "clf_DT.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf_DT.predict(X)\n",
    "accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier, recommended hyper parameters: \n",
      "\n",
      "{\"criterion\": [\"gini\", \"entropy\"], \"max_depth\": [2, 3, 4, 5]}\n",
      "doc ref: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
      "web ref: https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n"
     ]
    }
   ],
   "source": [
    "params_DT = fxGridSearch(iris, 'species', clf_DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>0.953333</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>0.953333</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  criterion max_depth  mean_test_score  rank_test_score\n",
       "2      gini         4         0.966667                1\n",
       "3      gini         5         0.966667                1\n",
       "1      gini         3         0.960000                3\n",
       "5   entropy         3         0.960000                3\n",
       "6   entropy         4         0.953333                5\n",
       "7   entropy         5         0.953333                5\n",
       "0      gini         2         0.933333                7\n",
       "4   entropy         2         0.933333                7"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fxGridSearch(iris, 'species', clf_DT, params=params_DT, GSopt=\"GridSearch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "clf_xgb = XGBClassifier()\n",
    "clf_xgb.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf_xgb.predict(X)\n",
    "accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier, recommended hyper parameters: \n",
      "\n",
      "{\"learning_rate\": [0.01, 0.1], \"n_estimators\": [100, 1000], \"max_depth\": [3, 4, 5], \"subsample\": [0.8, 0.1], \"colsample_bytree\": [0.3, 0.8], \"gamma\": [0, 1]}\n",
      "doc ref: https://xgboost.readthedocs.io/en/latest/parameter.html\n",
      "web ref: https://towardsdatascience.com/fine-tuning-xgboost-in-python-like-a-boss-b4543ed8b1e\n"
     ]
    }
   ],
   "source": [
    "params_xgb = fxGridSearch(iris, 'species', clf_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>gamma</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>subsample</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   colsample_bytree gamma learning_rate max_depth n_estimators subsample  \\\n",
       "22              0.3     0           0.1         5         1000       0.8   \n",
       "84              0.8     1           0.1         3          100       0.8   \n",
       "92              0.8     1           0.1         5          100       0.8   \n",
       "18              0.3     0           0.1         4         1000       0.8   \n",
       "14              0.3     0           0.1         3         1000       0.8   \n",
       "..              ...   ...           ...       ...          ...       ...   \n",
       "73              0.8     1          0.01         3          100       0.1   \n",
       "41              0.3     1           0.1         4          100       0.1   \n",
       "63              0.8     0           0.1         3         1000       0.1   \n",
       "67              0.8     0           0.1         4         1000       0.1   \n",
       "71              0.8     0           0.1         5         1000       0.1   \n",
       "\n",
       "    mean_test_score  rank_test_score  \n",
       "22         0.966667                1  \n",
       "84         0.966667                1  \n",
       "92         0.966667                1  \n",
       "18         0.966667                1  \n",
       "14         0.966667                1  \n",
       "..              ...              ...  \n",
       "73         0.940000               79  \n",
       "41         0.940000               79  \n",
       "63         0.940000               94  \n",
       "67         0.940000               94  \n",
       "71         0.940000               94  \n",
       "\n",
       "[96 rows x 8 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fxGridSearch(iris, 'species', clf_xgb, params=params_xgb, GSopt=\"GridSearch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
